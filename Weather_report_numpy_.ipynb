{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "66jMYEvo2e2U",
        "pKpwPXuL2e49",
        "9GalDJNl2e7m",
        "0kBGbXbo2fA3",
        "uamnkykk2fDg",
        "XcoV4__32fGP",
        "7IQGALjY2fIp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Weather_report_NumPy**\n",
        "\n",
        "> INVOLVE AND EVOLVE.\n",
        "\n",
        "\n",
        "> RUN ENGINES.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dnyRTLoO2ezq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating Data"
      ],
      "metadata": {
        "id": "66jMYEvo2e2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Number of samples\n",
        "n_samples = 1000\n",
        "\n",
        "# Generate random weather data: Temperature (T), Humidity (H), Pressure (P)\n",
        "temperature = np.random.normal(25, 5, n_samples)  # mean=25°C, std=5°C\n",
        "humidity = np.random.normal(60, 10, n_samples)    # mean=60%, std=10%\n",
        "pressure = np.random.normal(1013, 10, n_samples)  # mean=1013 hPa, std=10 hPa\n",
        "\n",
        "# Generate random labels (0: sunny, 1: rainy)\n",
        "rainy = (temperature < 22) & (humidity > 65) & (pressure < 1010)\n",
        "labels = rainy.astype(int)\n"
      ],
      "metadata": {
        "id": "AUHkk19P4x73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperature[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WGnfsfgELl3",
        "outputId": "65d6347a-12c2-41fe-f0d2-252020c5fe55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33.82026173, 27.00078604])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[30:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBXp1waO_436",
        "outputId": "adaacb51-7916-4e6e-db4c-6546e410438b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess Data"
      ],
      "metadata": {
        "id": "pKpwPXuL2e49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine into a single dataset\n",
        "X = np.column_stack((temperature, humidity, pressure))\n",
        "y = labels.reshape(-1, 1)\n",
        "\n",
        "# Add a column of ones to X for the bias term\n",
        "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "split_ratio = 0.8\n",
        "split_index = int(n_samples * split_ratio)\n",
        "\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n"
      ],
      "metadata": {
        "id": "yLulpmXX4zN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcrCBfF736YM",
        "outputId": "4b101d29-6e68-4fa0-9afe-b5bb8ec82f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00000000e+00, 3.38202617e+01, 6.55596268e+01, 9.97670789e+02],\n",
              "       [1.00000000e+00, 2.70007860e+01, 6.89247389e+01, 9.95880298e+02],\n",
              "       [1.00000000e+00, 2.98936899e+01, 5.57768518e+01, 1.01346135e+03],\n",
              "       ...,\n",
              "       [1.00000000e+00, 2.54709615e+01, 6.15843385e+01, 1.01107596e+03],\n",
              "       [1.00000000e+00, 1.92619453e+01, 4.85809858e+01, 1.00087484e+03],\n",
              "       [1.00000000e+00, 2.32094296e+01, 4.68902963e+01, 1.01219401e+03]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[12:45]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kt8Einw4CLD",
        "outputId": "953728b9-9d46-4e2a-fc3a-c09e61c37df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialize Parameters"
      ],
      "metadata": {
        "id": "9GalDJNl2e7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "weights = np.zeros((X.shape[1], 1))"
      ],
      "metadata": {
        "id": "5f-gxR6e4z4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMDtwki44ZGn",
        "outputId": "a557dbcc-a4e7-4b98-afbd-02af601cd37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Logistic Regression Functions\n",
        "\n"
      ],
      "metadata": {
        "id": "pztfexL12e-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **sigmoid(z)**\n",
        "\n",
        "**Purpose**: To apply the sigmoid function, which is used to map predictions to probabilities in logistic regression.\n",
        "\n",
        "**Explanation**:\n",
        "The sigmoid function takes any real-valued number and maps it to a value between 0 and 1. This is useful for binary classification, where we want to predict the probability that a given input belongs to a particular class.\n",
        "\n",
        "**Usage**:\n",
        "\n",
        "z is typically the dot product of the feature matrix\n",
        "𝑋\n",
        "X and the weight vector\n",
        "𝑤\n",
        "w.\n",
        "Returns the sigmoid-transformed value of\n",
        "𝑧\n",
        "z."
      ],
      "metadata": {
        "id": "0qUvkgnNAWgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n"
      ],
      "metadata": {
        "id": "3daU734641iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **predict(X, weights)**\n",
        "Purpose: To compute the predicted probabilities for the input features\n",
        "𝑋\n",
        "X using the current weights.\n",
        "\n",
        "Explanation:\n",
        "This function calculates the dot product of the feature matrix\n",
        "𝑋\n",
        "X and the weight vector\n",
        "𝑤\n",
        "w, and then applies the sigmoid function to the result to obtain the probabilities.\n",
        "\n",
        "**Usage**:\n",
        "\n",
        "X is the matrix of input features (with an added bias term).\n",
        "weights is the vector of model parameters.\n",
        "Returns the predicted probabilities for each sample in\n",
        "𝑋\n",
        "X."
      ],
      "metadata": {
        "id": "gtAeblS6AjVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, weights):\n",
        "  return sigmoid(np.dot(X, weights))"
      ],
      "metadata": {
        "id": "Ykt4jzp2AjGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. compute_cost(X, y, weights)\n",
        "\n",
        "Purpose: To compute the cost (or loss) of the logistic regression model.\n",
        "\n",
        "Explanation:\n",
        "The cost function measures how well the model's predictions match the actual data. For logistic regression, the cost function is derived from the likelihood of the observed data and is given by the binary cross-entropy (log-loss) function.\n",
        "\n",
        "Mathematical Formulation:\n",
        "\n",
        "𝐽\n",
        "(\n",
        "𝑤\n",
        ")\n",
        "=\n",
        "−\n",
        "1\n",
        "𝑚\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑚\n",
        "[\n",
        "𝑦\n",
        "(\n",
        "𝑖\n",
        ")\n",
        "log\n",
        "⁡\n",
        "(\n",
        "ℎ\n",
        "𝑤\n",
        "(\n",
        "𝑥\n",
        "(\n",
        "𝑖\n",
        ")\n",
        ")\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "−\n",
        "𝑦\n",
        "(\n",
        "𝑖\n",
        ")\n",
        ")\n",
        "log\n",
        "⁡\n",
        "(\n",
        "1\n",
        "−\n",
        "ℎ\n",
        "𝑤\n",
        "(\n",
        "𝑥\n",
        "(\n",
        "𝑖\n",
        ")\n",
        ")\n",
        ")\n",
        "]\n",
        "J(w)=−\n",
        "m\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "m\n",
        "​\n",
        " [y\n",
        "(i)\n",
        " log(h\n",
        "w\n",
        "​\n",
        " (x\n",
        "(i)\n",
        " ))+(1−y\n",
        "(i)\n",
        " )log(1−h\n",
        "w\n",
        "​\n",
        " (x\n",
        "(i)\n",
        " ))]\n",
        "where\n",
        "ℎ\n",
        "𝑤\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "𝜎\n",
        "(\n",
        "𝑤\n",
        "𝑇\n",
        "𝑥\n",
        ")\n",
        "h\n",
        "w\n",
        "​\n",
        " (x)=σ(w\n",
        "T\n",
        " x) is the hypothesis.\n",
        "\n",
        " **Usage**:\n",
        "\n",
        "X is the matrix of input features.\n",
        "y is the vector of true labels.\n",
        "weights is the vector of model parameters.\n",
        "Returns the computed cost (scalar value)."
      ],
      "metadata": {
        "id": "fkJ-2qhVAixm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, weights):\n",
        "    m = len(y)\n",
        "    h = predict(X, weights)\n",
        "    cost = -1/m * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "    return cost"
      ],
      "metadata": {
        "id": "Wf_aQR3rAiji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. gradient_descent(X, y, weights, learning_rate, iterations)\n",
        "Purpose: To perform gradient descent optimization to minimize the cost function and update the weights.\n",
        "\n",
        "Explanation:\n",
        "Gradient descent is an iterative optimization algorithm used to find the minimum of a function. In the context of logistic regression, it is used to minimize the cost function by updating the weights in the direction of the steepest descent (negative gradient).\n",
        "\n",
        "Steps:\n",
        "\n",
        "Compute the gradient of the cost function with respect to each weight.\n",
        "Update the weights by subtracting the product of the learning rate and the gradient.\n",
        "Mathematical Formulation:\n",
        "\n",
        "𝑤\n",
        ":\n",
        "=\n",
        "𝑤\n",
        "−\n",
        "𝛼\n",
        "1\n",
        "𝑚\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑚\n",
        "(\n",
        "ℎ\n",
        "𝑤\n",
        "(\n",
        "𝑥\n",
        "(\n",
        "𝑖\n",
        ")\n",
        ")\n",
        "−\n",
        "𝑦\n",
        "(\n",
        "𝑖\n",
        ")\n",
        ")\n",
        "𝑥\n",
        "(\n",
        "𝑖\n",
        ")\n",
        "w:=w−α\n",
        "m\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "m\n",
        "​\n",
        " (h\n",
        "w\n",
        "​\n",
        " (x\n",
        "(i)\n",
        " )−y\n",
        "(i)\n",
        " )x\n",
        "(i)\n",
        "\n",
        "where\n",
        "𝛼\n",
        "α is the learning rate."
      ],
      "metadata": {
        "id": "4uvcCVPLAiQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, weights, learning_rate, iterations):\n",
        "    m = len(y)\n",
        "    cost_history = np.zeros(iterations)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        weights -= learning_rate * (1/m) * np.dot(X.T, (predict(X, weights) - y))\n",
        "        cost_history[i] = compute_cost(X, y, weights)\n",
        "\n",
        "    return weights, cost_history\n"
      ],
      "metadata": {
        "id": "PcHQE8c7Ahki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Usage**:\n",
        "\n",
        "X is the matrix of input features.\n",
        "\n",
        "y is the vector of true labels.\n",
        "\n",
        "weights is the vector of model parameters.\n",
        "\n",
        "learning_rate is a hyperparameter that controls the step size in each iteration.\n",
        "\n",
        "iterations is the number of iterations to perform.\n",
        "\n",
        "Returns the optimized weights and the history of the cost function over iterations."
      ],
      "metadata": {
        "id": "o06JfOeJDAAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the Model"
      ],
      "metadata": {
        "id": "0kBGbXbo2fA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "# Train the model\n",
        "weights, cost_history = gradient_descent(X_train, y_train, weights, learning_rate, iterations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSax6ddJ42UV",
        "outputId": "86d366db-fd1e-4a4e-d3e8-0f3c04babf11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n",
            "<ipython-input-41-79fb628300cc>:4: RuntimeWarning: divide by zero encountered in log\n",
            "  cost = -1/m * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
            "<ipython-input-41-79fb628300cc>:4: RuntimeWarning: invalid value encountered in multiply\n",
            "  cost = -1/m * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make Predictions"
      ],
      "metadata": {
        "id": "uamnkykk2fDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_prob = predict(X_test, weights)\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26zrSB85463m",
        "outputId": "4fbf62ff-605c-4f52-f944-a0eb31d98bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate the Model"
      ],
      "metadata": {
        "id": "XcoV4__32fGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = np.mean(y_pred == y_test) * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYjW3U5I47hA",
        "outputId": "daa4f5d0-e3c7-4ebb-bc03-9232e296bd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SIMPLE Weather Report"
      ],
      "metadata": {
        "id": "7IQGALjY2fIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature_now= float(input(\"Enter the present temperature ranges between (0 to 60)*c:\\n\"))\n",
        "humidity_now= float(input(\"Enter the present humidity ranges between (0 to 100)%:\\n\"))\n",
        "pressure_now= float(input(\"Enter the present pressure ranges between (0 to 3000)hpa:\\n\"))\n",
        "\n",
        "# Combine into a single dataset\n",
        "X_test_now = np.column_stack((humidity_now,temperature_now,pressure_now))\n",
        "# Add a column of ones to X for the bias term\n",
        "X_test_now = np.hstack((np.ones((X_test_now.shape[0], 1)), X_test_now))\n",
        "y_pred_prob_now = predict(X_test_now, weights)\n",
        "\n",
        "print('the rainfall probabilty', y_pred_prob_now*100)\n",
        "print('the sunny probabilty', 100-y_pred_prob_now*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_Fyv1F27UE3",
        "outputId": "87f5e69c-f78a-4af6-e36c-53c6c78904d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the present temperature ranges between (0 to 60)*c:\n",
            "25\n",
            "Enter the present humidity ranges between (0 to 100)%:\n",
            "30\n",
            "Enter the present pressure ranges between (0 to 3000)hpa:\n",
            "1000\n",
            "the rainfall probabilty [[0.]]\n",
            "the sunny probabilty [[100.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-dc64dee5606b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YOUR TASK IS TO MAKE THIS **SIMPLE WEATHER REPORT** EVEN MORE **PRECISE** with your OWN Technics.  \n",
        "\n",
        "---\n",
        "**Tag\n",
        "your Github reposite , who ever finished Task**"
      ],
      "metadata": {
        "id": "dfF4BvXH2fMG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bFQltVFYCLrZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}